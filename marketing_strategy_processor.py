
import json
import re
from datetime import datetime
from database_setup import TauntResearchDB
import logging

class MarketingStrategyProcessor:
    def __init__(self):
        self.db = TauntResearchDB()
        
        # ë§ˆì¼€íŒ… ì „ëµ í•µì‹¬ í‚¤ì›Œë“œ ë§¤í•‘
        self.strategy_keywords = {
            "target_personas": {
                "ê²½ìŸì  ê²Œì´ë¨¸": ["ê²Œì´ë¨¸", "íŠ¸ìœ„ì¹˜", "ë””ìŠ¤ì½”ë“œ", "ì¸ë²¤", "íŠ¸ë˜ì‹œ í† í¬", "ê²½ìŸì‹¬", "ë°˜ì‚¬ì‹ ê²½"],
                "ì˜¨ë¼ì¸ í† ë¡ ê°€": ["í† ë¡ ê°€", "í´ë¦¬ì•™", "ë½ë¿Œ", "ë…¼ë¦¬", "ì¦ê±°", "ìˆ˜ì‚¬í•™", "íŒ©íŠ¸í­ë ¥"],
                "í’ì ì• í˜¸ê°€": ["í’ì", "ë°ˆ", "í‹±í†¡", "ì•„ì´ëŸ¬ë‹ˆ", "ëƒ‰ì†Œ", "ì¬ì¹˜", "ëŒë ¤ê¹Œê¸°"]
            },
            "viral_tactics": {
                "ì „êµ­ ë“œë¦½ë ¥ ê²½ì§„ëŒ€íšŒ": ["ê²½ì§„ëŒ€íšŒ", "ê²½ìŸ", "ë“œë¦½ë ¥", "ì¬ì¹˜", "ìœ„íŠ¸"],
                "ë„ë°œ ì•„ë ˆë‚˜": ["ì•„ë ˆë‚˜", "ì¸í„°ë™í‹°ë¸Œ", "ì›¹ ë°ëª¨", "ë°”ì´ëŸ´", "ê³µìœ "],
                "A-B ì½˜í…ì¸ ": ["ë¹„êµ", "ì¼ë°˜ AI", "ì¡°ë¡± AI", "ëŒ€ë¹„ íš¨ê³¼", "ìˆí¼"]
            },
            "monetization": {
                "WaaS": ["ìœ„íŠ¸ ê¸°ë°˜ ì„œë¹„ìŠ¤", "Wit-as-a-Service", "í”„ë¦¬ë¯¸ì—„", "êµ¬ë…"],
                "API": ["ì¡°ë¡± API", "B2B", "í†µí•©", "ì¸í”„ë¼"],
                "ì»¤ë®¤ë‹ˆí‹°": ["ë””ìŠ¤ì½”ë“œ ê¸¸ë“œ", "ìŠˆí¼ ìœ ì €", "ì¶©ì„±ë„", "ë…ì  ì½˜í…ì¸ "]
            },
            "content_types": {
                "íŒ©íŠ¸í­ë ¥": ["ë…¼ë¦¬ì ", "ì¦ê±° ê¸°ë°˜", "í† ë¡  ì¢…ê²°", "ê°ì •ì  ë¬´ë ¥í™”"],
                "ë§ì¤„ì„í‘œ ë„ë°œ": ["ì‹¬ë¦¬ì „", "ê¸´ì¥ê°", "ë¯¸ì™„ì„± ìœ„í˜‘", "ìì´ê°€ë¥´ë‹‰ íš¨ê³¼"],
                "ì¿¨ì°ì‹ ëƒ‰ì†Œ": ["ì´ˆì›”ì ", "ì•„ì´ëŸ¬ë‹ˆ", "ì§€ì  ìš°ì›”ê°", "ì´ˆì—°í•¨"],
                "ì”¹ì„ ë¹„ì‹ í›ˆê³„": ["ë„ë•ì  ìš°ìœ„", "ì •ì˜ë¡œìš´ ë¶„ë…¸", "ë‚™ì¸"],
                "ëŒë ¤ê¹Œê¸°": ["ìˆ˜ë™-ê³µê²©ì ", "ì¹­ì°¬ ì† ë¹„ë‚œ", "ë¯¸ë¬˜í•œ ì¹¨ìŠµ"]
            }
        }
        
        # ì‹¬ë¦¬í•™ì  ê¸°ë²• ë§¤í•‘
        self.psychological_techniques = {
            "ìì´ê°€ë¥´ë‹‰ íš¨ê³¼": {
                "description": "ë¯¸ì™„ì„±ëœ ê³¼ì œë‚˜ ì¤‘ë‹¨ëœ í™œë™ì— ëŒ€í•œ ê¸°ì–µì´ ë” ì˜¤ë˜ ë‚¨ëŠ” í˜„ìƒ",
                "application": "ë§ì¤„ì„í‘œ ë„ë°œì—ì„œ ìƒëŒ€ë°©ì´ ìŠ¤ìŠ¤ë¡œ ëª¨ìš•ì„ ì™„ì„±í•˜ë„ë¡ ìœ ë„",
                "effectiveness_score": 9.2
            },
            "ê³µì†ì„± ì´ë¡ ": {
                "description": "ë¸Œë¼ìš´ê³¼ ë ˆë¹ˆìŠ¨ì˜ ì–¸ì–´í•™ì  ê³µì†ì„± í”„ë ˆì„ì›Œí¬",
                "application": "í‘œë©´ì  ì˜ˆì˜ ë’¤ì— ìˆ¨ê¸´ ë„ë°œê³¼ ë¹„íŒ",
                "effectiveness_score": 8.7
            },
            "í€ì¹­ ì—…": {
                "description": "ê¶Œë ¥ìë‚˜ ë¶€ì¡°ë¦¬í•œ ì‚¬ìƒì„ ë¹„íŒí•˜ëŠ” ìœ¤ë¦¬ì  í’ì ì›ì¹™",
                "application": "ê°œì¸ ê³µê²©ì´ ì•„ë‹Œ êµ¬ì¡°ì  ë¹„íŒìœ¼ë¡œ ì•ˆì „ì„± í™•ë³´",
                "effectiveness_score": 9.5
            }
        }
        
    def extract_strategy_elements(self, text):
        """ë§ˆì¼€íŒ… ì „ëµ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ìš”ì†Œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        extracted_data = {
            "personas": [],
            "tactics": [],
            "content_types": [],
            "psychological_elements": [],
            "kpis": [],
            "viral_mechanics": []
        }
        
        text_lower = text.lower()
        
        # íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ
        for persona, keywords in self.strategy_keywords["target_personas"].items():
            if any(keyword in text_lower for keyword in keywords):
                extracted_data["personas"].append({
                    "name": persona,
                    "keywords_found": [kw for kw in keywords if kw in text_lower],
                    "strategy_priority": "high" if len([kw for kw in keywords if kw in text_lower]) > 3 else "medium"
                })
        
        # ë°”ì´ëŸ´ ì „ìˆ  ì¶”ì¶œ
        for tactic, keywords in self.strategy_keywords["viral_tactics"].items():
            if any(keyword in text_lower for keyword in keywords):
                extracted_data["tactics"].append({
                    "name": tactic,
                    "keywords_found": [kw for kw in keywords if kw in text_lower],
                    "implementation_phase": self._determine_phase(tactic)
                })
        
        # ì½˜í…ì¸  íƒ€ì… ì¶”ì¶œ
        for content_type, keywords in self.strategy_keywords["content_types"].items():
            if any(keyword in text_lower for keyword in keywords):
                extracted_data["content_types"].append({
                    "type": content_type,
                    "keywords_found": [kw for kw in keywords if kw in text_lower],
                    "psychological_basis": self._get_psychological_basis(content_type)
                })
        
        # KPI ë° ì„±ê³¼ ì§€í‘œ ì¶”ì¶œ
        kpi_patterns = [
            r"(\d+)%\s*ì¦ê°€", r"ë°”ì´ëŸ´ ê³„ìˆ˜", r"k-factor", 
            r"íŠ¸ë˜í”½\s*(\d+)%", r"ì‚¬ìš©ì\s*(\d+)ë§Œ", r"ì›” ë§¤ì¶œ\s*(\d+)ì–µ"
        ]
        
        for pattern in kpi_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                extracted_data["kpis"].extend(matches)
        
        return extracted_data
    
    def _determine_phase(self, tactic):
        """ì „ìˆ ì˜ êµ¬í˜„ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
        phase_mapping = {
            "ì „êµ­ ë“œë¦½ë ¥ ê²½ì§„ëŒ€íšŒ": "ë¡ ì¹­",
            "ë„ë°œ ì•„ë ˆë‚˜": "ì‚¬ì „ ë¡ ì¹­",
            "A-B ì½˜í…ì¸ ": "ì„±ì¥"
        }
        return phase_mapping.get(tactic, "ì¼ë°˜")
    
    def _get_psychological_basis(self, content_type):
        """ì½˜í…ì¸  íƒ€ì…ì˜ ì‹¬ë¦¬í•™ì  ê¸°ë°˜ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        basis_mapping = {
            "íŒ©íŠ¸í­ë ¥": "ì¸ì§€ì  ìš°ì›”ê°",
            "ë§ì¤„ì„í‘œ ë„ë°œ": "ìì´ê°€ë¥´ë‹‰ íš¨ê³¼",
            "ì¿¨ì°ì‹ ëƒ‰ì†Œ": "ì§€ì  ê¶Œìœ„",
            "ì”¹ì„ ë¹„ì‹ í›ˆê³„": "ë„ë•ì  ìš°ì›”ê°",
            "ëŒë ¤ê¹Œê¸°": "ì‚¬íšŒì  ì§€ë°°"
        }
        return basis_mapping.get(content_type, "ì¼ë°˜ì  ì‹¬ë¦¬")
    
    def process_marketing_strategy(self, strategy_text):
        """ë§ˆì¼€íŒ… ì „ëµì„ ì²˜ë¦¬í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        logging.info("ğŸ¯ ë§ˆì¼€íŒ… ì „ëµ NLP ì²˜ë¦¬ ì‹œì‘...")
        
        # ì „ëµ ìš”ì†Œ ì¶”ì¶œ
        extracted_data = self.extract_strategy_elements(strategy_text)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        with self.db.get_connection() as conn:
            with conn.cursor() as cur:
                # ë§ˆì¼€íŒ… ì „ëµ í…Œì´ë¸”ì´ ì—†ë‹¤ë©´ ìƒì„±
                cur.execute("""
                    CREATE TABLE IF NOT EXISTS marketing_strategy_data (
                        id SERIAL PRIMARY KEY,
                        strategy_type VARCHAR(100),
                        element_name VARCHAR(200),
                        keywords_found TEXT[],
                        metadata JSONB,
                        priority_level VARCHAR(50),
                        implementation_phase VARCHAR(50),
                        psychological_basis VARCHAR(100),
                        effectiveness_score FLOAT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """)
                
                # íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ ì €ì¥
                for persona in extracted_data["personas"]:
                    cur.execute("""
                        INSERT INTO marketing_strategy_data 
                        (strategy_type, element_name, keywords_found, metadata, priority_level, implementation_phase)
                        VALUES (%s, %s, %s, %s, %s, %s)
                    """, (
                        "target_persona",
                        persona["name"],
                        persona["keywords_found"],
                        json.dumps(persona),
                        persona["strategy_priority"],
                        "íƒ€ê²ŸíŒ…"
                    ))
                
                # ë°”ì´ëŸ´ ì „ìˆ  ì €ì¥
                for tactic in extracted_data["tactics"]:
                    cur.execute("""
                        INSERT INTO marketing_strategy_data 
                        (strategy_type, element_name, keywords_found, metadata, implementation_phase, effectiveness_score)
                        VALUES (%s, %s, %s, %s, %s, %s)
                    """, (
                        "viral_tactic",
                        tactic["name"],
                        tactic["keywords_found"],
                        json.dumps(tactic),
                        tactic["implementation_phase"],
                        8.5  # ê¸°ë³¸ íš¨ê³¼ì„± ì ìˆ˜
                    ))
                
                # ì½˜í…ì¸  íƒ€ì… ì €ì¥
                for content in extracted_data["content_types"]:
                    cur.execute("""
                        INSERT INTO marketing_strategy_data 
                        (strategy_type, element_name, keywords_found, metadata, psychological_basis, effectiveness_score)
                        VALUES (%s, %s, %s, %s, %s, %s)
                    """, (
                        "content_type",
                        content["type"],
                        content["keywords_found"],
                        json.dumps(content),
                        content["psychological_basis"],
                        self._get_content_effectiveness(content["type"])
                    ))
                
                # ì‹¬ë¦¬í•™ì  ê¸°ë²• ì €ì¥
                for technique, data in self.psychological_techniques.items():
                    cur.execute("""
                        INSERT INTO marketing_strategy_data 
                        (strategy_type, element_name, metadata, psychological_basis, effectiveness_score)
                        VALUES (%s, %s, %s, %s, %s)
                    """, (
                        "psychological_technique",
                        technique,
                        json.dumps(data),
                        data["description"],
                        data["effectiveness_score"]
                    ))
                
                conn.commit()
        
        logging.info("âœ… ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        return extracted_data
    
    def _get_content_effectiveness(self, content_type):
        """ì½˜í…ì¸  íƒ€ì…ë³„ íš¨ê³¼ì„± ì ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        effectiveness_scores = {
            "íŒ©íŠ¸í­ë ¥": 9.1,
            "ë§ì¤„ì„í‘œ ë„ë°œ": 8.8,
            "ì¿¨ì°ì‹ ëƒ‰ì†Œ": 8.3,
            "ì”¹ì„ ë¹„ì‹ í›ˆê³„": 7.9,
            "ëŒë ¤ê¹Œê¸°": 8.6
        }
        return effectiveness_scores.get(content_type, 7.5)
    
    def integrate_with_existing_prompts(self):
        """ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œê³¼ ë§ˆì¼€íŒ… ì „ëµì„ í†µí•©í•©ë‹ˆë‹¤."""
        logging.info("ğŸ”— ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ë§ˆì¼€íŒ… ì „ëµ í†µí•© ì¤‘...")
        
        with self.db.get_connection() as conn:
            with conn.cursor() as cur:
                # ë§ˆì¼€íŒ… ì „ëµ ë°ì´í„° ì¡°íšŒ
                cur.execute("""
                    SELECT strategy_type, element_name, psychological_basis, effectiveness_score, metadata
                    FROM marketing_strategy_data
                    WHERE effectiveness_score > 8.0
                    ORDER BY effectiveness_score DESC;
                """)
                
                high_impact_strategies = cur.fetchall()
                
                # ê¸°ì¡´ QA íˆìŠ¤í† ë¦¬ì— ë§ˆì¼€íŒ… ì „ëµ íƒœê·¸ ì¶”ê°€
                for strategy in high_impact_strategies:
                    strategy_type, element_name, psych_basis, score, metadata = strategy
                    
                    # ê´€ë ¨ QA ê¸°ë¡ ì—…ë°ì´íŠ¸
                    cur.execute("""
                        UPDATE qa_history 
                        SET marketing_strategy_applied = COALESCE(marketing_strategy_applied, '[]'::jsonb) || %s::jsonb
                        WHERE tone_used LIKE %s OR target_subject LIKE %s;
                    """, (
                        json.dumps({
                            "strategy": element_name,
                            "psychological_basis": psych_basis,
                            "effectiveness_score": score
                        }),
                        f"%{element_name}%",
                        f"%{element_name}%"
                    ))
                
                conn.commit()
        
        logging.info("âœ… ë§ˆì¼€íŒ… ì „ëµ í†µí•© ì™„ë£Œ")
    
    def generate_strategy_insights(self):
        """ë§ˆì¼€íŒ… ì „ëµ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        with self.db.get_connection() as conn:
            with conn.cursor() as cur:
                # ê°€ì¥ íš¨ê³¼ì ì¸ ì „ëµ ì¡°í•© ë¶„ì„
                cur.execute("""
                    SELECT 
                        element_name,
                        psychological_basis,
                        effectiveness_score,
                        COUNT(*) as usage_count
                    FROM marketing_strategy_data msd
                    LEFT JOIN qa_history qh ON qh.marketing_strategy_applied::text LIKE '%' || msd.element_name || '%'
                    WHERE strategy_type = 'content_type'
                    GROUP BY element_name, psychological_basis, effectiveness_score
                    ORDER BY effectiveness_score DESC, usage_count DESC;
                """)
                
                strategy_performance = cur.fetchall()
                
                insights = []
                for strategy, psych_basis, score, usage in strategy_performance:
                    insights.append({
                        "strategy": strategy,
                        "psychological_basis": psych_basis,
                        "effectiveness": score,
                        "usage_frequency": usage,
                        "recommendation": self._generate_recommendation(strategy, score, usage)
                    })
                
                return insights
    
    def _generate_recommendation(self, strategy, score, usage):
        """ì „ëµë³„ ë§ì¶¤ ì¶”ì²œì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if score > 9.0 and usage < 10:
            return f"{strategy} ì „ëµì€ ë†’ì€ íš¨ê³¼ì„±ì„ ë³´ì´ë¯€ë¡œ ë” ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤."
        elif score > 8.5 and usage > 50:
            return f"{strategy} ì „ëµì€ ì˜ í™œìš©ë˜ê³  ìˆìœ¼ë©°, ë³€í˜• ë²„ì „ ê°œë°œì„ ê³ ë ¤í•´ë³´ì„¸ìš”."
        elif score < 8.0:
            return f"{strategy} ì „ëµì˜ íš¨ê³¼ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
        else:
            return f"{strategy} ì „ëµì€ ê· í˜•ì¡íŒ ì„±ê³¼ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."

# ì‹¤ì œ ë§ˆì¼€íŒ… ì „ëµ í…ìŠ¤íŠ¸ ì²˜ë¦¬
def process_marketing_document():
    """ì²¨ë¶€ëœ ë§ˆì¼€íŒ… ì „ëµ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    
    # ì²¨ë¶€ íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ ë§ˆì¼€íŒ… ì „ëµ í…ìŠ¤íŠ¸
    marketing_strategy_text = """
    ì¡°ë¡± í”„ë¡œì íŠ¸ - í­ë°œì  ì‹œì¥ ì§€ë°°ë¥¼ ìœ„í•œ ì „ëµ ì²­ì‚¬ì§„
    
    í•µì‹¬ ì „ëµ: ê°•ë ¥í•œ íŒŒê¸‰ë ¥ì„ ì§€ë‹Œ ì¸í„°ë™í‹°ë¸Œ ë¡ ì¹­ ìº í˜ì¸, íŠ¹ì • ì˜¨ë¼ì¸ í•˜ìœ„ë¬¸í™” ì •ë°€ íƒ€ê²Ÿ ì¹¨íˆ¬, ì¶©ì„±ë„ ë†’ì€ ìŠˆí¼ ìœ ì € ì»¤ë®¤ë‹ˆí‹° ìœ¡ì„±
    
    í•µì‹¬ ì•„ì´ë””ì–´: ì „êµ­ ë“œë¦½ë ¥ ê²½ì§„ëŒ€íšŒ - ì‚¬ìš©ìë“¤ì´ ì¡°ë¡± AIì™€ ìì‹ ì˜ ì¬ì¹˜ë¥¼ ê²¨ë£¨ëŠ” ì¸í„°ë™í‹°ë¸Œ ì›¹ ë°ëª¨
    
    íƒ€ê²Ÿ ê³ ê°: ê²½ìŸì  ê²Œì´ë¨¸, ì˜¨ë¼ì¸ í† ë¡ ê°€, í’ì ì• í˜¸ê°€ (ì§€ì  ìš°ì›”ì„± ì¶”êµ¬, ìœ„íŠ¸ë¥¼ ì‚¬íšŒì  ìë³¸ìœ¼ë¡œ ê°„ì£¼)
    
    í•µì‹¬ AI ë„ë°œ ìœ í˜•:
    - íŒ©íŠ¸í­ë ¥: ë…¼ë¦¬ì ì´ê³  ì¦ê±° ê¸°ë°˜ì˜ í† ë¡  ì¢…ê²°ì ëª¨ë“œ
    - ë§ì¤„ì„í‘œ ë„ë°œ: ì‹¬ë¦¬ì „ ëª¨ë“œ, ìì´ê°€ë¥´ë‹‰ íš¨ê³¼ í™œìš©
    - ì¿¨ì°ì‹ ëƒ‰ì†Œ: ì´ˆì›”ì  ì§€ì„± ëª¨ë“œ, ì§€ì  ìš°ì›”ê° ê³¼ì‹œ
    - ì”¹ì„ ë¹„ì‹ í›ˆê³„: ì •ì˜ë¡œìš´ ë¶„ë…¸ ëª¨ë“œ, ë„ë•ì  ìš°ìœ„
    - ëŒë ¤ê¹Œê¸°: ë¯¸ë¬˜í•œ ì¹¨ìŠµ ëª¨ë“œ, ìˆ˜ë™-ê³µê²©ì  ì¬ì¹˜
    
    ë§ˆì¼€íŒ… ì „ëµ:
    1. ë„ë°œ ì•„ë ˆë‚˜ ì¸í„°ë™í‹°ë¸Œ ì›¹ ë°ëª¨
    2. A-B ì½˜í…ì¸  ì œì‘ (ì¼ë°˜ AI vs ì¡°ë¡± AI)
    3. ê³„ì¸µì  ì¸í”Œë£¨ì–¸ì„œ ì „ëµ (ë©”ê°€/ë§¤í¬ë¡œ/ë§ˆì´í¬ë¡œ)
    4. ë””ìŠ¤ì½”ë“œ ì¡°ë¡± ê¸¸ë“œ ì»¤ë®¤ë‹ˆí‹°
    
    ì„±ê³¼ ì§€í‘œ: ë°”ì´ëŸ´ ê³„ìˆ˜, íŠ¸ë˜í”½ 500% ì¦ê°€, ì‚¬ìš©ì ì°¸ì—¬ìœ¨
    """
    
    processor = MarketingStrategyProcessor()
    
    # ì „ëµ ì²˜ë¦¬ ë° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    extracted_data = processor.process_marketing_strategy(marketing_strategy_text)
    
    # ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•©
    processor.integrate_with_existing_prompts()
    
    # ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insights = processor.generate_strategy_insights()
    
    return extracted_data, insights

if __name__ == "__main__":
    extracted_data, insights = process_marketing_document()
    
    print("\n" + "="*60)
    print("ğŸ¯ ë§ˆì¼€íŒ… ì „ëµ NLP ì²˜ë¦¬ ì™„ë£Œ")
    print("="*60)
    
    print(f"\nğŸ“Š ì¶”ì¶œëœ ë°ì´í„°:")
    print(f"  â€¢ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜: {len(extracted_data['personas'])}ê°œ")
    print(f"  â€¢ ë°”ì´ëŸ´ ì „ìˆ : {len(extracted_data['tactics'])}ê°œ")
    print(f"  â€¢ ì½˜í…ì¸  íƒ€ì…: {len(extracted_data['content_types'])}ê°œ")
    
    print(f"\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
    for insight in insights[:3]:
        print(f"  ğŸ” {insight['strategy']}: {insight['recommendation']}")

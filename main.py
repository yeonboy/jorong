from dotenv import load_dotenv
load_dotenv()
import os
import logging
import sys
import json
from datetime import datetime
from flask import Flask, render_template, request, jsonify, session
from werkzeug.middleware.proxy_fix import ProxyFix

# Google Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import google.generativeai as genai

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from prompt_builder import get_research_enhanced_prompt
from prompt_config import TONE_DESCRIPTIONS

DATABASE_AVAILABLE = False # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ê¸°ëŠ¥ ë¹„í™œì„±í™”

# UTF-8 ì¸ì½”ë”© ì„¤ì • (Replit í™˜ê²½ì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìŒ)
if sys.version_info[0] == 3:
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

app = Flask(__name__)
# ì„¸ì…˜ ê´€ë¦¬ë¥¼ ìœ„í•œ ë¹„ë°€ í‚¤ ì„¤ì • (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë” ê°•ë ¥í•œ í‚¤ ì‚¬ìš© ê¶Œì¥)
app.secret_key = os.environ.get('FLASK_SECRET_KEY', 'super-secret-key-for-jorong')
app.wsgi_app = ProxyFix(app.wsgi_app) # í”„ë¡ì‹œ í™˜ê²½ì—ì„œ IP ì£¼ì†Œ ì¶”ì¶œì„ ìœ„í•´ í•„ìš”

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ====================================================================
# Google Gemini API ì„¤ì •
# ====================================================================
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    logging.error("GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    genai.configure(api_key=GEMINI_API_KEY)
    logging.info("Google Gemini APIê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")




@app.route('/')
def index():
    """
    ë©”ì¸ í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤. (ì¡°ë¡± ì‚¬ì´íŠ¸ì˜ ì…ë ¥ í¼)
    """
    return render_template('index.html')

@app.route('/dashboard')
def dashboard():
    """
    ë…¸ì…˜ ì—°ë™ìš© ëŒ€ì‹œë³´ë“œ í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    return render_template('dashboard.html')



@app.route('/generate_taunt_text', methods=['POST'])
def generate_taunt_text():
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ Gemini APIë¥¼ í†µí•´ ì¡°ë¡± í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not GEMINI_API_KEY:
        logging.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ ìƒì„±ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return jsonify({'status': 'error', 'message': 'ì„œë²„ ì„¤ì • ì˜¤ë¥˜: Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500

    try:
        data = request.get_json()
        target = data.get('target')
        keywords = data.get('keywords')
        tone = data.get('tone', 'ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ')
        length = data.get('length', 500)
        darkness_level = data.get('darkness_level', 2)

        if not target or not keywords:
            logging.warning("í•„ìˆ˜ ì…ë ¥ í•„ë“œ ëˆ„ë½: ëŒ€ìƒ ë˜ëŠ” í‚¤ì›Œë“œ")
            return jsonify({'status': 'error', 'message': 'ì¡°ë¡± ëŒ€ìƒê³¼ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.'}), 400

        logging.info(f"ì¡°ë¡± í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­: ëŒ€ìƒ='{target}', í‚¤ì›Œë“œ='{keywords}', í†¤='{tone}', í‘í™” ë‹¨ê³„='{darkness_level}', ê¸¸ì´='{length}'")

        # 1. ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìƒì„±ê³¼ ì•ˆì „ì„± ê²€ì‚¬ë¥¼ ë™ì‹œì— ìš”ì²­)
        prompt_text = get_research_enhanced_prompt(target, keywords, tone, darkness_level, length, optimized_for_json=True)

        # 2. Gemini API í˜¸ì¶œ 1íšŒ (JSON ëª¨ë“œ)
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(
            prompt_text,
            generation_config=genai.types.GenerationConfig(response_mime_type="application/json")
        )
        
        # 3. API ì‘ë‹µ íŒŒì‹±
        try:
            result_json = json.loads(response.text)
            generated_text = result_json.get('generated_text', 'ì˜¤ë¥˜: í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
            post_generation_safety_analysis = result_json.get('safety_analysis', {'is_safe': False, 'safety_message': 'ì•ˆì „ì„± ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'})
        except json.JSONDecodeError:
            logging.error(f"JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ: {response.text}")
            generated_text = response.text.strip()
            post_generation_safety_analysis = {'is_safe': True, 'safety_message': 'ê¸°ë³¸ ì•ˆì „ì„± ê²€ì‚¬ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤.'}

        logging.info(f"ìƒì„±ëœ ì¡°ë¡± í…ìŠ¤íŠ¸: {generated_text[:100]}...")
        logging.info(f"ì•ˆì „ì„± ê²€ì‚¬ ê²°ê³¼: {post_generation_safety_analysis}")

        # ë™ì  ë¶„ì„ ê²°ê³¼ ìƒì„± (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        tone_config = TONE_DESCRIPTIONS.get(tone, {})
        emotion_strategies = tone_config.get('emotion_strategy', ['empathy'])
        primary_emotions = { 'superiority': 'ìš°ì›”ê° ìê·¹', 'empathy': 'ê³µê°ëŒ€ í˜•ì„±', 'catharsis': 'ì¹´íƒ€ë¥´ì‹œìŠ¤', 'social_validation': 'ì‚¬íšŒì  ìŠ¹ì¸' }
        primary_emotion = primary_emotions.get(emotion_strategies[0], 'ìœ ë¨¸ëŸ¬ìŠ¤') if emotion_strategies else 'ìœ ë¨¸ëŸ¬ìŠ¤'
        intensity_map = { range(0, 300): 'ë³´í†µ', range(300, 600): 'ë†’ìŒ', range(600, 1000): 'ë§¤ìš° ë†’ìŒ', range(1000, 2000): 'ê·¹ë„ë¡œ ë†’ìŒ' }
        intensity_level = next((level for r, level in intensity_map.items() if length in r), 'ë³´í†µ')
        tone_techniques = {
            'ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ': ['ê³¼ì¥ë²•', 'ìƒí™© ë¹„ìœ ', 'ì¼ìƒ ì—°ê²°'], 'í’ìì ': ['ì€ìœ ë²•', 'ì•„ì´ëŸ¬ë‹ˆ', 'ì‚¬íšŒ ë¹„íŒ'], 'ë¹„ê¼¬ëŠ” ë“¯ì´': ['ë°˜ì–´ë²•', 'ì•”ì‹œ', 'ê°„ì ‘ í‘œí˜„'],
            'ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ë°•í•˜ëŠ”': ['íŒ©íŠ¸ ì²´í¬', 'ë…¼ë¦¬ì  êµ¬ì¡°', 'ê·¼ê±° ì œì‹œ'], 'MZ ë°˜ë§ í†¤': ['ìŠ¬ë­ í™œìš©', 'ì¤„ì„ë§', 'ì„¸ëŒ€ ê³µê°'], 'ì• êµ í†¤': ['ì˜ì¸ë²•', 'ê·€ì—¬ìš´ í‘œí˜„', 'ë¶€ë“œëŸ¬ìš´ ë¹„íŒ'],
            'í—¬ì°½ í†¤': ['ìš´ë™ ë¹„ìœ ', 'ì—ë„ˆì§€ í‘œí˜„', 'ë™ê¸°ë¶€ì—¬ ìš”ì†Œ'], 'ê°ì„± ì—ì„¸ì´ í†¤': ['ê°ì • ì´ì…', 'ì‹œì  í‘œí˜„', 'ë‚´ë©´ ë¬˜ì‚¬'], 'í•´ì‹œíƒœê·¸ ìŠ¤íƒ€ì¼': ['í‚¤ì›Œë“œ ë‚˜ì—´', 'SNS ë¬¸ë²•', 'íŠ¸ë Œë“œ ë°˜ì˜'],
            'ì—ê²í†¤': ['ê³ ê¸‰ ì–´íœ˜', 'í’ˆê²© ìˆëŠ” ë¹„íŒ', 'ìš°ì•„í•œ í‘œí˜„'], 'ì†Œì‹¬í•œ ê³µê²© í†¤': ['Aposiopesis ê¸°ë²•', 'ë§ì¤„ì„ ì¡°ë¡±', 'ìœ„ì„ ì  ìˆ˜ìŠµ'], 'ë§ì¤„ì„ ë°ˆ í†¤': ['Aposiopesis ê¸°ë²•', 'ë°ˆ ë¬¸í™” ìœµí•©', 'ë°”ì´ëŸ´ ìµœì í™”'],
            'ì¸ì§€ ë¶€ì¡°í™” ìœ ë°œ í†¤': ['ë…¼ë¦¬ì  ëª¨ìˆœ ë…¸ì¶œ', 'ì¸ì§€ ë¶€ì¡°í™” ìœ ë°œ', 'ì‹ ë… ì²´ê³„ ê³µê²©'], 'ê°ì • ì¡°ì‘ ì—­ê³µ í†¤': ['ê°ì • ì¡°ì‘ íƒì§€', 'ì‹¬ë¦¬ì  ë°©ì–´', 'ì£¼ë„ê¶Œ ì—­ì „'],
            'ë…¼ë¦¬ì  í•´ì²´ í†¤': ['ì²´ê³„ì  ë¶„ì„', 'ë‹¨ê³„ë³„ ë…¼ë°•', 'í—ˆì  ë“œëŸ¬ë‚´ê¸°'], 'ì‹¬ë¦¬ì  ìš°ìœ„ ì ë ¹ í†¤': ['ì•½ì  íŒŒì•…', 'ì‹¬ë¦¬ì  ì••ë°•', 'ìš°ìœ„ ì ë ¹'], 'ì¸ì§€ì  ìš°ìœ„ ê³¼ì‹œ í†¤': ['ì§€ì  ê²©ì°¨ ë¶€ê°', 'ì‚¬ê³  ê¹Šì´ ê³¼ì‹œ', 'ì¸ì§€ ëŠ¥ë ¥ ìš°ì›”ê°']
        }
        recommended_approaches = tone_techniques.get(tone, ['ê³¼ì¥ë²•', 'ì•„ì´ëŸ¬ë‹ˆ', 'ë¹„ìœ '])

        dynamic_emotion_analysis = {
            'primary_emotion': primary_emotion, 'intensity_level': intensity_level, 'recommended_approaches': recommended_approaches,
            'psychological_target': tone_config.get('psychological_hook', 'ë…ìì˜ ê³µê°ê³¼ ì¬ë¯¸ ìœ ë°œ'), 'emotion_strategy': emotion_strategies,
        }

        # í’ˆì§ˆ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        tone_complexity_scores = { 'ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê²Œ': 80, 'í’ìì ': 90, 'ë¹„ê¼¬ëŠ” ë“¯ì´': 85, 'ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ë°•í•˜ëŠ”': 95, 'MZ ë°˜ë§ í†¤': 75, 'ì• êµ í†¤': 70, 'í—¬ì°½ í†¤': 75, 'ê°ì„± ì—ì„¸ì´ í†¤': 88, 'í•´ì‹œíƒœê·¸ ìŠ¤íƒ€ì¼': 72, 'ì—ê²í†¤': 98, 'ì •ì‹ ë‚˜ê°„ í†¤': 85, 'í…Œí†  í†¤': 82 }
        base_quality = tone_complexity_scores.get(tone, 80)
        length_bonus = min(length // 100 * 2, 20)
        dynamic_quality_analysis = {
            'readability_score': min(base_quality + length_bonus, 100), 'originality_score': min(base_quality + (len(emotion_strategies) * 5), 100),
            'humor_rating': round(min(base_quality / 20, 5.0), 1), 'emotion_targeting_score': len(emotion_strategies) * 25,
            'predicted_virality': 'High' if len(emotion_strategies) >= 2 else 'Medium'
        }

        return jsonify({
            'status': 'success',
            'letter': generated_text,
            'emotion_analysis': dynamic_emotion_analysis,
            'quality_analysis': dynamic_quality_analysis,
            'post_generation_safety_analysis': post_generation_safety_analysis,
            'qa_history_id': None, # DB ë¹„í™œì„±í™”
            'gemini_model_info': {
                'model_name': 'Gemini 1.5 Flash', 'version': '1.5', 'emotion_targeting_enabled': True,
                'psychological_analysis_enabled': True, 'qa_logging_enabled': DATABASE_AVAILABLE
            }
        })

    except Exception as e:
        logging.error(f"ì¡°ë¡± í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜: {str(e)}")
        if "API key not valid" in str(e):
             return jsonify({'status': 'error', 'message': 'API í‚¤ ë¬¸ì œ: Google Gemini API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.'}), 500
        return jsonify({'status': 'error', 'message': f'í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500


@app.route('/analyze_taunt', methods=['POST'])
def analyze_taunt():
    """ìƒì„±ëœ ì¡°ë¡± í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    if not GEMINI_API_KEY:
        logging.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return jsonify({'status': 'error', 'message': 'API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 500

    try:
        data = request.get_json()
        # --- ë¬¸ì œ í•´ê²° 3: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚¸ 'taunt_text' í‚¤ë¡œ ìˆ˜ì • ---
        text = data.get('taunt_text', '')

        if not text:
            return jsonify({'status': 'error', 'message': 'ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400

        logging.info(f"ì¡°ë¡± í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì²­: {text[:100]}...")

        analysis_prompt = f"""
ë‹¤ìŒ ì¡°ë¡± í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

"{text}"

ë‹¤ìŒ í•­ëª©ë“¤ì„ JSON í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
{{
  "humor_level": "1-5ì  ì‚¬ì´ì˜ ìˆ«ì",
  "wit_score": "1-5ì  ì‚¬ì´ì˜ ìˆ«ì",
  "safety_concern": "ì•ˆì „ì„± ìš°ë ¤ì‚¬í•­ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ìš”ì•½",
  "safety_details": "ì•ˆì „ì„± ê´€ë ¨ ìƒì„¸ ì„¤ëª…ì„ í•œêµ­ì–´ë¡œ ì‘ì„±",
  "improvement_suggestions": ["ê°œì„  ì œì•ˆì„ í•œêµ­ì–´ë¡œ ì‘ì„±", "ë‘ ë²ˆì§¸ ê°œì„  ì œì•ˆì„ í•œêµ­ì–´ë¡œ ì‘ì„±"]
}}

ì¤‘ìš”: ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ì˜ì–´ ë‹¨ì–´ë‚˜ ë¬¸ì¥ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""

        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(
            analysis_prompt,
            generation_config=genai.types.GenerationConfig(response_mime_type="application/json")
        )

        analysis_result = json.loads(response.text)
        logging.info(f"ë¶„ì„ ì™„ë£Œ: ìœ ë¨¸ ìˆ˜ì¤€ {analysis_result.get('humor_level', 'N/A')}")

        return jsonify({
            'status': 'success',
            'analysis': analysis_result
        })

    except json.JSONDecodeError as e:
        logging.error(f"ë¶„ì„ ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        return jsonify({ 'status': 'error', 'message': 'ë¶„ì„ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' }), 500
    except Exception as e:
        logging.error(f"ì¡°ë¡± í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        return jsonify({ 'status': 'error', 'message': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}' }), 500


@app.route('/get_darkness_levels', methods=['GET'])
def get_darkness_levels():
    """í‘í™” ë‹¨ê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from prompt_config import DARKNESS_CONFIG
    
    darkness_levels = []
    for level, config in DARKNESS_CONFIG.items():
        darkness_levels.append({
            "level": level,
            "name": config["name"],
            "description": config["approach"]
        })
    
    return jsonify({ 'status': 'success', 'levels': darkness_levels })


# --- ë¬¸ì œ í•´ê²° 1: ë¹„í™œì„±í™”ëœ ê´€ë¦¬ì/ë¶„ì„ ê¸°ëŠ¥ ì£¼ì„ ì²˜ë¦¬ ---
# @app.route('/admin/analytics', methods=['GET']) ...
# @app.route('/admin/analytics/download', methods=['GET']) ...
# @app.route('/admin/analytics/realtime', methods=['GET']) ...
# @app.route('/admin/export_training_data', methods=['GET']) ...
# @app.route('/admin/add_cnn_development_request', methods=['POST']) ...
# @app.route('/admin/view_development_queue', methods=['GET']) ...
# @app.route('/admin/viral_analysis', methods=['POST']) ...
# @app.route('/admin/feedback_loop_status', methods=['GET']) ...
# @app.route('/admin/real_time_learning', methods=['POST']) ...
# @app.route('/admin/scrape_training_data', methods=['POST']) ...
# @app.route('/admin/data_sources', methods=['GET']) ...
# @app.route('/admin/performance_metrics', methods=['GET']) ...


@app.route('/api/project/status', methods=['GET'])
def get_project_status():
    """ë…¸ì…˜ìš© í”„ë¡œì íŠ¸ í˜„í™© API"""
    try:
        status_data = {
            'project_name': 'ì¡°ë¡± í”„ë¡œì íŠ¸',
            'version': '2.0',
            'status': 'active',
            'last_updated': datetime.now().isoformat(),
            'features': {
                'ai_generation': 'active',
                'safety_analysis': 'active',
                'tone_variations': len(TONE_DESCRIPTIONS),
                'darkness_levels': 5
            },
            'statistics': {
                'total_tones': len(TONE_DESCRIPTIONS),
                'database_status': 'inactive' if not DATABASE_AVAILABLE else 'active',
                'api_status': 'active' if GEMINI_API_KEY else 'inactive'
            },
            'categories': {
                'strategy': 'ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½',
                'research': 'ì‹¬ë¦¬í•™ ê¸°ë°˜ ì—°êµ¬',
                'development': 'ê¸°ëŠ¥ ê°œë°œ í˜„í™©',
                'analytics': 'ì‚¬ìš©ì ë¶„ì„'
            }
        }

        return jsonify({
            'status': 'success',
            'data': status_data,
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        logging.error(f"í”„ë¡œì íŠ¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/project/categories', methods=['GET'])
def get_project_categories():
    """ë…¸ì…˜ìš© í”„ë¡œì íŠ¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ API"""
    try:
        categories = {
            'strategy': {
                'name': 'ì „ëµ',
                'description': 'ë§ˆì¼€íŒ… ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ',
                'items': [
                    'ë°”ì´ëŸ´ ë§ˆì¼€íŒ… ì „ëµ',
                    'ì‚¬ìš©ì íƒ€ê²ŸíŒ…',
                    'í”Œë«í¼ë³„ ìµœì í™”',
                    'ìˆ˜ìµí™” ëª¨ë¸'
                ],
                'status': 'in_progress'
            },
            'research': {
                'name': 'ì—°êµ¬',
                'description': 'ì‹¬ë¦¬í•™ ë° ì–¸ì–´í•™ ì—°êµ¬',
                'items': [
                    'Aposiopesis ê¸°ë²• ì—°êµ¬',
                    'ì—ê²-í…Œí†  í˜ë¥´ì†Œë‚˜ ë¶„ì„',
                    'ê°ì •ì„  íƒ€ê²ŸíŒ… ì‹œìŠ¤í…œ',
                    'ë°”ì´ëŸ´ í™”ë²• ë¶„ì„'
                ],
                'status': 'active'
            },
            'development': {
                'name': 'ê°œë°œ',
                'description': 'ê¸°ìˆ ì  êµ¬í˜„ ë° ê¸°ëŠ¥ ê°œë°œ',
                'items': [
                    'AI ëª¨ë¸ ìµœì í™”',
                    'ì•ˆì „ì„± ê²€ì‚¬ ì‹œìŠ¤í…œ',
                    'ì‹¤ì‹œê°„ ë¶„ì„ ê¸°ëŠ¥',
                    'UI/UX ê°œì„ '
                ],
                'status': 'ongoing'
            },
            'analytics': {
                'name': 'ë¶„ì„',
                'description': 'ì‚¬ìš©ì ë° ì„±ê³¼ ë¶„ì„',
                'items': [
                    'ì‚¬ìš©ì í–‰ë™ ë¶„ì„',
                    'ì½˜í…ì¸  ì„±ê³¼ ì¸¡ì •',
                    'íŠ¸ë Œë“œ ë¶„ì„',
                    'í”¼ë“œë°± ì‹œìŠ¤í…œ'
                ],
                'status': 'planning'
            }
        }

        return jsonify({
            'status': 'success',
            'categories': categories,
            'total_categories': len(categories),
            'timestamp': datetime.now().isoformat()
        })

    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/notion/dashboard', methods=['GET'])
def get_notion_dashboard():
    """ë…¸ì…˜ ëŒ€ì‹œë³´ë“œìš© ì¢…í•© ë°ì´í„° API"""
    try:
        dashboard_data = {
            'overview': {
                'project_health': 'healthy',
                'active_features': len([k for k in TONE_DESCRIPTIONS.keys()]),
                'completion_rate': '75%',
                'next_milestone': 'ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ ì™„ì„±'
            },
            'recent_activities': [
                {
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'activity': 'ì¡°ë¡± ë¶„ì„ í•œêµ­ì–´ ì¶œë ¥ ìˆ˜ì • ì™„ë£Œ',
                    'category': 'development'
                },
                {
                    'date': (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d'),
                    'activity': 'ì•ˆì „ì„± ê²€ì‚¬ ì‹œìŠ¤í…œ ê°•í™”',
                    'category': 'research'
                }
            ],
            'performance_metrics': {
                'api_response_time': '< 2ì´ˆ',
                'system_uptime': '99.5%',
                'user_satisfaction': '4.2/5.0',
                'feature_adoption': '68%'
            },
            'priorities': [
                {'task': 'ë…¸ì…˜ ì—°ë™ ì™„ì„±', 'priority': 'high', 'deadline': '2025-07-15'},
                {'task': 'ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”', 'priority': 'medium', 'deadline': '2025-07-20'},
                {'task': 'ìƒˆë¡œìš´ í†¤ ê°œë°œ', 'priority': 'low', 'deadline': '2025-07-30'}
            ]
        }

        return jsonify({
            'status': 'success',
            'dashboard': dashboard_data,
            'generated_at': datetime.now().isoformat()
        })

    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

if __name__ == '__main__':
    logging.info("âš ï¸ ì—°êµ¬ ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    logging.info("ğŸš€ ê¸°ë³¸ ëª¨ë“œì—ì„œë„ ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)


@app.route('/admin/load_reddit_training_data', methods=['POST'])
def load_reddit_training_data():
    """Reddit í•™ìŠµ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        from reddit_training_data_processor import RedditTrainingDataProcessor

        processor = RedditTrainingDataProcessor()

        # 2025ë…„ Reddit íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ
        reddit_data = [
            {
                "source": "reddit_korea",
                "title": "2025ë…„ ì„œìš¸ ì›”ì„¸ ì‹¤í™”ì¸ê°€ìš”? ì¢…ë¡œì—ì„œ 5í‰ì— 100ë§Œì›ì´ë¼ëŠ”ë°â€¦",
                "content": "ìµœê·¼ì— ì§‘ ì•Œì•„ë³´ëŠ”ë° ì •ë§ ìˆ¨ì´ í„± ë§‰íˆë„¤ìš”. ë‹¤ë“¤ ì´ì •ë„ ë‚´ê³  ì‚¬ì‹œëŠ” ê±´ê°€ìš”?",
                "score": 850,
                "num_comments": 452,
                "subreddit": "korea",
                "data_type": "community_post"
            },
            {
                "source": "reddit_korea", 
                "title": "í•œêµ­ ì§ì¥ ë‚´ ì„¸ëŒ€ ê°ˆë“±, ì—¬ëŸ¬ë¶„ íšŒì‚¬ëŠ” ì–´ë–¤ê°€ìš”?",
                "content": "ìš”ì¦˜ MZì„¸ëŒ€ë‘ ê¸°ì„±ì„¸ëŒ€ë‘ ì¼í•˜ëŠ” ë°©ì‹ ì°¨ì´ ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ë„¤ìš”.",
                "score": 510,
                "num_comments": 288,
                "subreddit": "korea",
                "data_type": "community_post"
            }
        ]

        # ë°ì´í„° ì²˜ë¦¬
        processed_data = processor.process_reddit_data(reddit_data)
        insights = processor.generate_training_insights(processed_data)

        # ì„¸ì…˜ì— ì €ì¥ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©)
        session['reddit_training_data'] = processed_data
        session['reddit_insights'] = insights

        return jsonify({
            'status': 'success',
            'message': 'Reddit í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ',
            'data': {
                'total_samples': insights['total_samples'],
                'trend_distribution': insights['trend_distribution'],
                'top_emotion_triggers': insights['top_emotion_triggers'][:5],
                'recommended_tones': insights['recommended_tones'][:5]
            }
        })

    except Exception as e:
        logging.error(f"Reddit í•™ìŠµ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
        }), 500

@app.route('/admin/reddit_insights', methods=['GET'])
def get_reddit_insights():
    """Reddit ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        insights = session.get('reddit_insights', {})

        if not insights:
            return jsonify({
                'status': 'error',
                'message': 'Reddit ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.'
            }), 400

        return jsonify({
            'status': 'success',
            'insights': insights,
            'recommendations': [
                {
                    'category': 'íŠ¸ë Œë“œ ë°˜ì˜',
                    'insight': f"ê°€ì¥ ì¸ê¸°ìˆëŠ” íŠ¸ë Œë“œëŠ” '{max(insights['trend_distribution'], key=insights['trend_distribution'].get)}'ì…ë‹ˆë‹¤.",
                    'recommendation': 'ì´ íŠ¸ë Œë“œì— íŠ¹í™”ëœ í†¤ê³¼ í‘œí˜„ì„ ê°œë°œí•˜ì„¸ìš”.'
                },
                {
                    'category': 'ê°ì • íƒ€ê²ŸíŒ…',
                    'insight': f"ê°€ì¥ íš¨ê³¼ì ì¸ ê°ì • íŠ¸ë¦¬ê±°ëŠ” '{insights['top_emotion_triggers'][0][0]}'ì…ë‹ˆë‹¤.",
                    'recommendation': 'ì´ ê°ì • íŠ¸ë¦¬ê±°ë¥¼ í™œìš©í•œ ì½˜í…ì¸  ìƒì„±ì„ ê°•í™”í•˜ì„¸ìš”.'
                },
                {
                    'category': 'í’ˆì§ˆ ìµœì í™”',
                    'insight': f"í‰ê·  í’ˆì§ˆ ì ìˆ˜ëŠ” {insights['quality_distribution']['average']:.2f}ì ì…ë‹ˆë‹¤.",
                    'recommendation': 'ê³ í’ˆì§ˆ ë°ì´í„° ë¹„ìœ¨ì„ ë†’ì´ê¸° ìœ„í•œ í•„í„°ë§ ê¸°ì¤€ì„ ê°•í™”í•˜ì„¸ìš”.'
                }
            ]
        })

    except Exception as e:
        logging.error(f"Reddit ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/admin/load_news_youtube_data', methods=['POST'])
def load_news_youtube_data():
    """ë‰´ìŠ¤/ìœ íŠœë¸Œ ëŒ“ê¸€ í•™ìŠµ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        from news_youtube_training_processor import NewsYoutubeTrainingProcessor

        processor = NewsYoutubeTrainingProcessor()

        # ë‰´ìŠ¤/ìœ íŠœë¸Œ ëŒ“ê¸€ ë°ì´í„° ë¡œë“œ
        comment_data = [
            {
                "source": "simulated_naver_news_comment",
                "title": "[ì†ë³´] ì •ë¶€, 3ê¸° ì‹ ë„ì‹œ ì¶”ê°€ ê³µê¸‰ ë° DSR ê·œì œ ì™„í™” ë°œí‘œ",
                "content": "ì´ê²Œ ëŒ€ì±…ì´ë¼ê³  ë‚´ë†“ì€ê±´ê°€? ì§‘ê°’ ì¡ì„ ìƒê°ì€ ì—†ê³  ê·¸ëƒ¥ ê±´ì„¤ì‚¬ë“¤ ë°°ë§Œ ë¶ˆë ¤ì£¼ìëŠ” ê±°ì–ì•„. ì„œë¯¼ë“¤ì€ ì–´ì°¨í”¼ ëŒ€ì¶œë„ ì•ˆë‚˜ì™€ì„œ ê·¸ë¦¼ì˜ ë–¡ì„.",
                "score": 5820,
                "num_comments": 1250,
                "data_type": "policy_criticism",
                "speech_pattern": "news_comment_cynical",
                "emotional_intensity": 9.3,
                "stance": "negative"
            },
            {
                "source": "simulated_youtube_comment",
                "title": "ì˜í™” 'ê´‘í•´ 2' ì˜ˆê³ í¸ ìµœì´ˆ ê³µê°œ! ë°°ìš° ì´ë³‘í—Œ 1ì¸ 2ì—­ ë³µê·€",
                "content": "ì™€... ì˜ˆê³ í¸ë§Œ ë´¤ëŠ”ë° ë²Œì¨ ëª…ì‘ ìŠ¤ë©œì´ ë‚œë‹¤. ì´ë³‘í—Œ ì—°ê¸°ëŠ” ì§„ì§œ êµ­ë³´ê¸‰ì´ë„¤. ì²œë§Œ ê´€ê° ê·¸ëƒ¥ ë„˜ì„ ë“¯ ã„·ã„·",
                "score": 12000,
                "num_comments": 3400,
                "data_type": "entertainment_reaction",
                "speech_pattern": "youtube_comment_praise",
                "emotional_intensity": 9.0,
                "stance": "positive"
            },
            {
                "source": "simulated_daum_news_comment",
                "title": "ì—­ëŒ€ê¸‰ í­ì—¼ì— ì „ë ¥ìˆ˜ê¸‰ 'ê²½ê³ 'â€¦ 7ì›”ì¸ë° ë²Œì¨ 38ë„",
                "content": "ì§€êµ¬ê°€ ì§„ì§œ ì•„í”„ê¸´ í•œê°€ ë³´ë„¤ìš”... ë‹¤ë“¤ ë”ìœ„ ì¡°ì‹¬í•˜ì‹œê³ , íŠ¹íˆ ì•¼ì™¸ì—ì„œ ì¼í•˜ì‹œëŠ” ë¶„ë“¤ ì •ë§ ê³ ìƒ ë§ìœ¼ì‹­ë‹ˆë‹¤. ì •ë¶€ëŠ” ì „ê¸°ì„¸ ì§€ì› ê°™ì€ ëŒ€ì±… ì¢€ ì„¸ì›Œì£¼ì„¸ìš”.",
                "score": 3500,
                "num_comments": 880,
                "data_type": "social_concern",
                "speech_pattern": "news_comment_empathetic",
                "emotional_intensity": 7.5,
                "stance": "concerned_neutral"
            },
            {
                "source": "simulated_youtube_comment",
                "title": "ìš”ì¦˜ MZ ì‹ ì…ì‚¬ì› íŠ¹ì§•.mp4 (feat. ë¼ë–¼ëŠ” ë§ì´ì•¼)",
                "content": "ã…‹ã…‹ã…‹ã…‹ã…‹ ê°œì›ƒê¸°ë„¤ ì§„ì§œ ìš°ë¦¬ íšŒì‚¬ ë¶€ì¥ë‹˜ ë³´ëŠ” ì¤„. ê·¼ë° ì†”ì§íˆ ì„œë¡œ ì´í•´í•˜ë ¤ëŠ” ë…¸ë ¥ì´ í•„ìš”í•¨. ì €ë ‡ê²Œê¹Œì§€ í•˜ëŠ” ì‹ ì…ì€ ì—†ì§€ë§Œ ì–´ëŠ ì •ë„ ê³µê°ì€ ê°„ë‹¤.",
                "score": 8800,
                "num_comments": 2100,
                "data_type": "generational_humor",
                "speech_pattern": "youtube_comment_relatable",
                "emotional_intensity": 8.2,
                "stance": "humorous_neutral"
            },
            {
                "source": "simulated_naver_news_comment",
                "title": "ë…¼ë€ì˜ 'OOOë²•' êµ­íšŒ í†µê³¼â€¦ ì‹œë¯¼ë‹¨ì²´ ê°•ë ¥ ë°˜ë°œ",
                "content": "ì´ê²Œ ë¯¼ì£¼ì£¼ì˜ êµ­ê°€ ë§ëƒ? êµ­ë¯¼ ì˜ê²¬ì€ ì‹¹ ë‹¤ ë¬´ì‹œí•˜ê³  ê·¸ëƒ¥ ë°€ì–´ë¶™ì´ë„¤. ë‹¤ìŒ ì„ ê±° ë•Œ ë³´ì.",
                "score": 7600,
                "num_comments": 3200,
                "data_type": "political_opposition",
                "speech_pattern": "news_comment_aggressive",
                "emotional_intensity": 9.8,
                "stance": "strong_negative"
            },
            {
                "source": "simulated_youtube_comment",
                "title": "[4K ì§ìº ] XXX ì•„ì´ëŒ ì‹ ê³¡ 'FANTASY' ì‡¼ì¼€ì´ìŠ¤ ë¬´ëŒ€",
                "content": "ì•Œê³ ë¦¬ì¦˜ë‹˜, ì €ë¥¼ ì´ê³³ìœ¼ë¡œ ì¸ë„í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤... ë§¤ì¼ ë³´ëŸ¬ ì˜¤ê² ìŠµë‹ˆë‹¤. 1ì¼ 1ì§ìº  í•„ìˆ˜.",
                "score": 25000,
                "num_comments": 5500,
                "data_type": "fandom_worship",
                "speech_pattern": "youtube_comment_fandom",
                "emotional_intensity": 9.5,
                "stance": "strong_positive"
            },
            {
                "source": "simulated_daum_news_comment",
                "title": "[ë‹¨ë…] ìœ ëª… ì—°ì˜ˆì¸ OOO, 100ì–µëŒ€ ê±´ë¬¼ ë§¤ì…",
                "content": "ì´ëŸ° ê¸°ì‚¬ ì¢€ ì•ˆ ë³´ê³  ì‹¶ë‹¤. ìƒëŒ€ì  ë°•íƒˆê°ë§Œ ë“œë„¤. ì„œë¯¼ë“¤ì€ í•œ í‰ìƒ ëª¨ì•„ë„ ëŒ€ì¶œ ê°šê¸° í˜ë“ ë°...",
                "score": 4100,
                "num_comments": 1500,
                "data_type": "social_criticism",
                "speech_pattern": "news_comment_despair",
                "emotional_intensity": 8.0,
                "stance": "negative"
            },
            {
                "source": "simulated_youtube_comment",
                "title": "10ë¶„ë§Œì— ì´í•´í•˜ëŠ” ì–‘ìì—­í•™",
                "content": "ì™€... ì„¤ëª…ì„ ë„ˆë¬´ ì˜í•´ì£¼ì…”ì„œ ë¬¸ê³¼ìƒì¸ë° ì²˜ìŒìœ¼ë¡œ ì´í•´í–ˆì–´ìš”. 10ë¶„ ìˆœì‚­ì´ë„¤ìš”. êµ¬ë…í•˜ê³  ê°‘ë‹ˆë‹¤!",
                "score": 15000,
                "num_comments": 2800,
                "data_type": "educational_feedback",
                "speech_pattern": "youtube_comment_appreciation",
                "emotional_intensity": 7.0,
                "stance": "positive"
            }
        ]

        # ë°ì´í„° ì²˜ë¦¬
        processed_data = processor.process_news_youtube_data(comment_data)
        insights = processor.generate_insights(processed_data)

        # ì„¸ì…˜ì— ì €ì¥
        session['news_youtube_data'] = processed_data
        session['news_youtube_insights'] = insights

        return jsonify({
            'status': 'success',
            'message': 'ë‰´ìŠ¤/ìœ íŠœë¸Œ ëŒ“ê¸€ í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ',
            'data': {
                'total_samples': insights['total_samples'],
                'platform_distribution': insights['platform_distribution'],
                'top_psychological_drivers': insights['top_psychological_drivers'][:5],
                'recommended_tones': insights['recommended_tones'][:5],
                'viral_analysis': insights['viral_potential_analysis']
            }
        })

    except Exception as e:
        logging.error(f"ë‰´ìŠ¤/ìœ íŠœë¸Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
        }), 500

@app.route('/admin/news_youtube_insights', methods=['GET'])
def get_news_youtube_insights():
    """ë‰´ìŠ¤/ìœ íŠœë¸Œ ëŒ“ê¸€ ë°ì´í„° ë¶„ì„ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        insights = session.get('news_youtube_insights', {})

        if not insights:
            return jsonify({
                'status': 'error',
                'message': 'ë‰´ìŠ¤/ìœ íŠœë¸Œ ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.'
            }), 400

        return jsonify({
            'status': 'success',
            'insights': insights,
            'recommendations': [
                {
                    'category': 'í”Œë«í¼ë³„ íŠ¹ì„±',
                    'insight': f"ê°€ì¥ ë§ì€ ë°ì´í„°ê°€ ìˆ˜ì§‘ëœ í”Œë«í¼ì€ '{max(insights['platform_distribution'], key=insights['platform_distribution'].get)}'ì…ë‹ˆë‹¤.",
                    'recommendation': 'ê° í”Œë«í¼ì˜ ê³ ìœ í•œ ì–¸ì–´ì  íŠ¹ì„±ì„ ë°˜ì˜í•œ í†¤ ê°œë°œì´ í•„ìš”í•©ë‹ˆë‹¤.'
                },
                {
                    'category': 'ì‹¬ë¦¬ì  ë™ê¸°',
                    'insight': f"ê°€ì¥ ê°•í•œ ì‹¬ë¦¬ì  ë™ê¸°ëŠ” '{insights['top_psychological_drivers'][0][0]}'ì…ë‹ˆë‹¤.",
                    'recommendation': 'ì´ ì‹¬ë¦¬ì  ë™ê¸°ë¥¼ ìê·¹í•˜ëŠ” ì½˜í…ì¸  ìƒì„± ì „ëµì„ ê°•í™”í•˜ì„¸ìš”.'
                },
                {
                    'category': 'ë°”ì´ëŸ´ ì ì¬ë ¥',
                    'insight': f"í‰ê·  ë°”ì´ëŸ´ ì ìˆ˜ëŠ” {insights['viral_potential_analysis']['average_viral_score']:.3f}ì…ë‹ˆë‹¤.",
                    'recommendation': f"ê³ ë°”ì´ëŸ´ ì½˜í…ì¸  {insights['viral_potential_analysis']['high_viral_count']}ê°œì˜ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì ìš©í•˜ì„¸ìš”."
                },
                {
                    'category': 'ê°ì • ê°•ë„',
                    'insight': f"ê·¹ê°• ê°ì • ëŒ“ê¸€ì´ {insights['emotional_intensity_stats']['extreme_count']}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                    'recommendation': 'ê°ì • ê°•ë„ê°€ ë†’ì€ ì½˜í…ì¸ ì˜ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ íš¨ê³¼ì ì¸ ì¡°ë¡± ì „ëµì„ ìˆ˜ë¦½í•˜ì„¸ìš”.'
                }
            ]
        })

    except Exception as e:
        logging.error(f"ë‰´ìŠ¤/ìœ íŠœë¸Œ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/admin/run_ai_learning', methods=['POST'])
def run_ai_learning():
    """3$ ì˜ˆì‚°ìœ¼ë¡œ AI ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    try:
        from ai_learning_pipeline import AILearningPipeline

        data = request.get_json()
        budget = data.get('budget', 3.0)

        if budget > 5.0:
            return jsonify({
                'status': 'error',
                'message': 'ì˜ˆì‚°ì€ ìµœëŒ€ $5ê¹Œì§€ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.'
            }), 400

        logging.info(f"ğŸ’° AI í•™ìŠµ ì‹œì‘ - ì˜ˆì‚°: ${budget}")

        # AI í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline = AILearningPipeline(budget_usd=budget)
        results = pipeline.run_full_pipeline()

        if results:
            # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥
            session['ai_learning_results'] = results

            return jsonify({
                'status': 'success',
                'message': f'AI í•™ìŠµ ì™„ë£Œ! ì´ ë¹„ìš©: ${results["total_cost"]:.3f}',
                'results': {
                    'data_processed': results['data_processed'],
                    'requests_used': results['requests_used'],
                    'total_cost': results['total_cost'],
                    'remaining_budget': results['remaining_budget'],
                    'efficiency_score': results['efficiency_score'],
                    'cost_per_data': results['total_cost'] / results['data_processed'] if results['data_processed'] > 0 else 0
                },
                'performance': {
                    'efficiency_rating': 'excellent' if results['efficiency_score'] > 15 else 'good',
                    'budget_utilization': (results['total_cost'] / budget) * 100,
                    'data_density': f"{results['data_processed']} ë°ì´í„° / ${results['total_cost']:.3f}"
                }
            })
        else:
            return jsonify({
                'status': 'error',
                'message': 'AI í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
            }), 500

    except ImportError:
        return jsonify({
            'status': 'error',
            'message': 'AI í•™ìŠµ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        }), 500
    except Exception as e:
        logging.error(f"AI í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': f'AI í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
        }), 500

@app.route('/admin/ai_learning_status', methods=['GET'])
def get_ai_learning_status():
    """AI í•™ìŠµ ìƒíƒœ ë° ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        results = session.get('ai_learning_results')

        if not results:
            return jsonify({
                'status': 'no_data',
                'message': 'AI í•™ìŠµì´ ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'suggestions': [
                    '/admin/run_ai_learning ì—”ë“œí¬ì¸íŠ¸ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ì„¸ìš”.',
                    'ì˜ˆì‚°ì€ $1-5 ì‚¬ì´ë¡œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.',
                    'í•™ìŠµ ë°ì´í„°ëŠ” Reddit + ë‰´ìŠ¤/ìœ íŠœë¸Œ ëŒ“ê¸€ í†µí•© ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.'
                ]
            })

        return jsonify({
            'status': 'success',
            'learning_results': results,
            'insights': {
                'cost_efficiency': f"${results['total_cost']:.3f}ë¡œ {results['data_processed']}ê°œ ë°ì´í„° ì²˜ë¦¬",
                'roi_analysis': f"ë°ì´í„°ë‹¹ ë¹„ìš©: ${results['total_cost'] / results['data_processed']:.4f}",
                'budget_management': f"ì˜ˆì‚° ì‚¬ìš©ë¥ : {(results['total_cost'] / 3.0) * 100:.1f}%",
                'performance_rating': 'excellent' if results['efficiency_score'] > 15 else 'good'
            },
            'next_actions': [
                'í•™ìŠµëœ íŒ¨í„´ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©í•˜ì—¬ ì„±ëŠ¥ ê°œì„ ',
                'A/B í…ŒìŠ¤íŠ¸ë¡œ ê°œì„  íš¨ê³¼ ì¸¡ì •',
                'ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° ì¶”ê°€ í•™ìŠµ'
            ]
        })

    except Exception as e:
        logging.error(f"AI í•™ìŠµ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500